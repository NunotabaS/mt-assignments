#!/usr/bin/env python
import optparse
import sys
import bleu
import math, random, re
from operator import itemgetter
import os.path as path
import pickle

def log (string):
  sys.stderr.write(string + "\n")
  
# Calculates a smoothed value for bleu
# Reference : SFU NLP Class
# 
# A modification of BLEU that returns a positive value even when some 
# higher-order precisions are zero. From Liang et al. 2006 (Footnote 5):
# http://aclweb.org/anthology-new/P/P06/P06-1096.pdf
def compute_bleu(sent, ref):
  stats = [stat for stat in bleu.bleu_stats(sent, ref)]
  return sum([bleu.bleu(stats[:2+2*i])/math.pow(2,4-i+1) for i in xrange(1,5)])

def find_untranslated (sent):
  count = 0
  for word in sent:
    if re.match(r"[\u0400-\u0500]+", word):
      count += 1
  return count

def extract_features(nbest):
  (hyp, bleu, feats) = nbest
  features = {'NULL': 1.0}
  for feat in feats.split(' '):
    (k, v) = feat.split('=')
    features[k] = float(v)
  features['len(s)'] = len(hyp.strip().split())
  features['untrans'] = find_untranslated(hyp.strip().split())
  return features

optparser = optparse.OptionParser()
optparser.add_option("-k", "--kbest-list", dest="input", default="data/dev+test.100best", help="100-best translation lists")
optparser.add_option("-t", "--tau", dest="tau", default=5000, type="int", help="Sample count (default 5000)")
optparser.add_option("-i", "--xi", dest="xi", default=100, type="int", help="Training data kept from samples (def 100)")
optparser.add_option("-a", "--alpha", dest="alpha", default=0.1, type="float", help="Sampler acceptance cutoff")
optparser.add_option("-e", "--eta", dest="eta", default=0.1, type="float", help="Perceptron learn rate")
optparser.add_option("-m", "--rounds", dest="rounds", default=5, type="int", help="Perceptron training rounds")
optparser.add_option("-r", "--reference", dest="reference", default="data/train.ref", help="Target language reference sentences")
optparser.add_option("-x", "--train", dest="train", default="data/train.100best", help="Target language training sentences")
optparser.add_option("-p", "--pickle", dest="pickle", default=False, help="Use pickle?")

(opts, _) = optparser.parse_args()

train_refs = [line.strip().split() for line in open(opts.reference)]
train_sents = [pair.split(' ||| ') for pair in open(opts.train)]
num_train = len(train_sents) / 100

all_hyps = [pair.split(' ||| ') for pair in open(opts.input)]
num_sents = len(all_hyps) / 100

# learn the weights
weights = {'NULL'       : 0.0,
           'p(e)'       : 0.0354159999966,
           'p(e|f)'     : -0.100677099999,
           'p_lex(f|e)' : -0.0138261000048,
           'len(s)'     : 0.0399999999994,
           'untrans'    : 0.0199999999997
           }

for s in xrange(0, num_sents):
  hyps_for_one_sent = all_hyps[s * 100:s * 100 + 100]
  (best_score, best) = (-1e300, '')
  for (num, hyp, feats) in hyps_for_one_sent:
    score = 0.0
    feats = extract_features((hyp, None, feats))
    score = sum(feats[w] * weights[w] for w in weights)
   
    if score > best_score:
      (best_score, best) = (score, hyp)
  try: 
    sys.stdout.write("%s\n" % best)
  except (Exception):
    sys.exit(1)


